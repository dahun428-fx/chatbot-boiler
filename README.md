# ğŸ¤– LLM Chatbot Boilerplate

<p align="center">
  <img src="https://img.shields.io/badge/TypeScript-5.0-blue?logo=typescript" alt="TypeScript" />
  <img src="https://img.shields.io/badge/React-18.3-61dafb?logo=react" alt="React" />
  <img src="https://img.shields.io/badge/Vite-6.0-646cff?logo=vite" alt="Vite" />
  <img src="https://img.shields.io/badge/TailwindCSS-3.4-38bdf8?logo=tailwindcss" alt="TailwindCSS" />
  <img src="https://img.shields.io/badge/License-MIT-green" alt="License" />
</p>

**í”„ë¡œë•ì…˜ ë ˆë””** TypeScript + React ê¸°ë°˜ì˜ LLM ì±—ë´‡ ë³´ì¼ëŸ¬í”Œë ˆì´íŠ¸ì…ë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ í•˜ë‚˜ë¡œ OpenAI, Anthropic, Google Geminië¥¼ ì „í™˜í•˜ê³ , ë°±ì—”ë“œ APIì™€ ì§ì ‘ LLM í˜¸ì¶œ ëª¨ë“œë¥¼ ììœ ë¡­ê²Œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì„¤ëª… |
|------|------|
| ğŸ”Œ **ë©€í‹° LLM ì§€ì›** | OpenAI, Anthropic Claude, Google Gemini ì–´ëŒ‘í„° ë‚´ì¥ |
| ğŸ”„ **ì„œë¹„ìŠ¤ ì¶”ìƒí™”** | í™˜ê²½ë³€ìˆ˜ë¡œ BackendAPI â†” LLMAPI ëª¨ë“œ ì „í™˜ |
| ğŸŒŠ **ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°** | SSE ê¸°ë°˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ + íƒ€ì´í•‘ ì• ë‹ˆë©”ì´ì…˜ |
| ğŸ”’ **API Key ë³´í˜¸** | Vite Proxyë¡œ ê°œë°œ í™˜ê²½ì—ì„œë„ API Key ìˆ¨ê¹€ |
| ğŸ“ **ë§ˆí¬ë‹¤ìš´ ë Œë”ë§** | GFM, ì½”ë“œ í•˜ì´ë¼ì´íŒ…, í…Œì´ë¸” ì§€ì› |
| ğŸ’¾ **ì„ íƒì  ì €ì¥** | LocalStorage ì €ì¥ on/off ì„¤ì • |
| ğŸŒ **ë‹¤êµ­ì–´ ì§€ì›** | i18next ê¸°ë°˜ (í•œêµ­ì–´/ì˜ì–´) |
| ğŸ§ª **TDD í…ŒìŠ¤íŠ¸** | Vitest + Testing Library (91ê°œ í…ŒìŠ¤íŠ¸) |
| ğŸ“± **ë°˜ì‘í˜• UI** | ëª¨ë°”ì¼/ë°ìŠ¤í¬í†± ì™„ë²½ ì§€ì› |

---

## ğŸ“‹ ëª©ì°¨

- [ë¹ ë¥¸ ì‹œì‘](#-ë¹ ë¥¸-ì‹œì‘)
- [í™˜ê²½ ë³€ìˆ˜ ì„¤ì •](#-í™˜ê²½-ë³€ìˆ˜-ì„¤ì •)
- [ì•„í‚¤í…ì²˜](#-ì•„í‚¤í…ì²˜)
- [LLM Provider ì„¤ì •](#-llm-provider-ì„¤ì •)
- [ChatService ì‚¬ìš©ë²•](#-chatservice-ì‚¬ìš©ë²•)
- [í…ŒìŠ¤íŠ¸](#-í…ŒìŠ¤íŠ¸)
- [í™•ì¥ ê°€ì´ë“œ](#-í™•ì¥-ê°€ì´ë“œ)
- [ê¸°ìˆ  ìŠ¤íƒ](#-ê¸°ìˆ -ìŠ¤íƒ)
- [í”„ë¡œì íŠ¸ êµ¬ì¡°](#-í”„ë¡œì íŠ¸-êµ¬ì¡°)

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ìš”êµ¬ ì‚¬í•­

- **Node.js**: â‰¥ 18.18 (Vite 6 ê¶Œì¥)
- **íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €**: Yarn (ê¶Œì¥) ë˜ëŠ” npm

### ì„¤ì¹˜ ë° ì‹¤í–‰

```bash
# 1. ì €ì¥ì†Œ í´ë¡ 
git clone https://github.com/your-repo/llm-chatbot-boilerplate.git
cd llm-chatbot-boilerplate

# 2. ì˜ì¡´ì„± ì„¤ì¹˜
yarn install

# 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env.local

# 4. ê°œë°œ ì„œë²„ ì‹¤í–‰ (http://localhost:3000)
yarn dev
```

### ì£¼ìš” ëª…ë ¹ì–´

| ëª…ë ¹ì–´ | ì„¤ëª… |
|--------|------|
| `yarn dev` | ê°œë°œ ì„œë²„ ì‹¤í–‰ (í¬íŠ¸ 3000) |
| `yarn build` | í”„ë¡œë•ì…˜ ë¹Œë“œ |
| `yarn preview` | ë¹Œë“œ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸° |
| `yarn test` | í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (watch ëª¨ë“œ) |
| `yarn test:run` | í…ŒìŠ¤íŠ¸ 1íšŒ ì‹¤í–‰ |
| `yarn test:coverage` | ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸ |
| `yarn lint` | ESLint ê²€ì‚¬ |
| `yarn storybook` | Storybook ì‹¤í–‰ |

---

## âš™ï¸ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

`.env.example`ì„ ë³µì‚¬í•˜ì—¬ `.env.local` ë˜ëŠ” `.env.development`ë¥¼ ìƒì„±í•˜ì„¸ìš”.

### ğŸ”¥ í•µì‹¬ ì„¤ì •

```bash
# ==============================================
# ChatService ì„¤ì •
# ==============================================

# ì„œë¹„ìŠ¤ íƒ€ì… ì„ íƒ
# - BackendAPI: ìì²´ ë°±ì—”ë“œ ì„œë²„ ê²½ìœ  (í”„ë¡œë•ì…˜ ê¶Œì¥)
# - LLMAPI: LLM API ì§ì ‘ í˜¸ì¶œ (ê°œë°œ/í”„ë¡œí† íƒ€ì…)
VITE_CHAT_SERVICE_TYPE=LLMAPI

# ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œ
VITE_STREAMING_MODE=true

# LocalStorage ì €ì¥
VITE_LOCALSTORAGE_SAVE=false

# íƒ€ì„ì•„ì›ƒ (ë°€ë¦¬ì´ˆ)
VITE_API_TIMEOUT_MS=30000

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
VITE_SYSTEM_PROMPT=You are a helpful assistant.
```

### ğŸ”Œ LLM Provider ì„¤ì •

```bash
# ==============================================
# LLM ì§ì ‘ í˜¸ì¶œ ì„¤ì • (VITE_CHAT_SERVICE_TYPE=LLMAPI ì‹œ)
# ==============================================

# Provider: openai | anthropic | gemini
VITE_LLM_PROVIDER=gemini

# ëª¨ë¸ëª…
VITE_LLM_MODEL=gemini-2.0-flash

# API Key ë³´ì•ˆ ì„¤ì •
# âš ï¸ VITE_ ì ‘ë‘ì‚¬ ì—†ìŒ = ë¸Œë¼ìš°ì €ì— ë…¸ì¶œë˜ì§€ ì•ŠìŒ!
LLM_API_KEY=your-api-key-here

# í”„ë¡ì‹œ ì‚¬ìš© (API Key ìˆ¨ê¹€)
VITE_LLM_USE_PROXY=true
```

### ğŸ–¥ï¸ Backend API ì„¤ì •

```bash
# ==============================================
# Backend API ì„¤ì • (VITE_CHAT_SERVICE_TYPE=BackendAPI ì‹œ)
# ==============================================

VITE_BACKEND_API_URL=http://localhost:8000/api/chat
```

> âš ï¸ **ë³´ì•ˆ ì£¼ì˜**: `.env.local` íŒŒì¼ì€ ì ˆëŒ€ Gitì— ì»¤ë°‹í•˜ì§€ ë§ˆì„¸ìš”!

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### ì„œë¹„ìŠ¤ ëª¨ë“œ ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ChatService ì¶”ìƒí™”                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚         BackendAPI ëª¨ë“œ          â”‚          LLMAPI ëª¨ë“œ           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Browser â†’ Your Backend â†’ LLM   â”‚   Browser â†’ Vite Proxy â†’ LLM  â”‚
â”‚                                 â”‚   (ê°œë°œí™˜ê²½, API Key ìˆ¨ê¹€)       â”‚
â”‚  âœ… í”„ë¡œë•ì…˜ ê¶Œì¥                   â”‚   âœ… ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘            â”‚
â”‚  âœ… API Key ì™„ì „ ë³´í˜¸              â”‚   âœ… ë°±ì—”ë“œ ì—†ì´ í…ŒìŠ¤íŠ¸           â”‚
â”‚  âœ… ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì¶”ê°€ ê°€ëŠ¥           â”‚   âš ï¸ í”„ë¡œë•ì…˜ì—ì„œëŠ” BackendAPI    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ë°ì´í„° íë¦„ (LLMAPI + Proxy)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Browser  â”‚â”€â”€â”€â–¶â”‚ /llm-proxy/...  â”‚â”€â”€â”€â–¶â”‚ Vite Dev Server  â”‚â”€â”€â”€â–¶â”‚ LLM API â”‚
â”‚          â”‚    â”‚ (API Key ì—†ìŒ)   â”‚    â”‚ (API Key ì£¼ì…)    â”‚    â”‚         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì»´í¬ë„ŒíŠ¸ ê³„ì¸µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     useChat (í†µí•© í›…)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚    useChatState       â”‚         useChatActions          â”‚
â”‚  (ì½ê¸° ì „ìš© ìƒíƒœ)        â”‚        (ì“°ê¸° ì „ìš© ì•¡ì…˜)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    Recoil Atoms                         â”‚
â”‚  messagesState | isLoadingState | streamingContentState â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    ChatService                          â”‚
â”‚          LLMAPIService | BackendAPIService              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    LLM Adapters                         â”‚
â”‚    OpenAIAdapter | AnthropicAdapter | GeminiAdapter     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ LLM Provider ì„¤ì •

### OpenAI

```bash
VITE_LLM_PROVIDER=openai
VITE_LLM_MODEL=gpt-4o
LLM_API_KEY=sk-...
VITE_LLM_USE_PROXY=true
```

### Google Gemini

```bash
VITE_LLM_PROVIDER=gemini
VITE_LLM_MODEL=gemini-2.0-flash
LLM_API_KEY=AIzaSy...
VITE_LLM_USE_PROXY=true
```

**ì‚¬ìš© ê°€ëŠ¥í•œ Gemini ëª¨ë¸:**
- `gemini-2.0-flash` (ì¶”ì²œ)
- `gemini-1.5-pro`
- `gemini-1.5-flash`

### Anthropic Claude

```bash
VITE_LLM_PROVIDER=anthropic
VITE_LLM_MODEL=claude-3-5-sonnet-20241022
LLM_API_KEY=sk-ant-...
VITE_LLM_USE_PROXY=true
```

---

## ğŸ’¬ ChatService ì‚¬ìš©ë²•

### 1. useChat í›… (ê¶Œì¥)

```tsx
import { useChat } from '@/features/chat';

const ChatPage = () => {
  const { 
    messages,           // ë©”ì‹œì§€ ëª©ë¡
    isLoading,          // ë¡œë”© ìƒíƒœ
    streamingContent,   // ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ í…ìŠ¤íŠ¸
    error,              // ì—ëŸ¬ ìƒíƒœ
    send,               // ë©”ì‹œì§€ ì „ì†¡
    abort,              // ìš”ì²­ ì·¨ì†Œ
    retry,              // ì¬ì‹œë„
    clear               // ëŒ€í™” ì´ˆê¸°í™”
  } = useChat();

  const handleSend = (text: string) => {
    send(text);
  };

  return (
    <div>
      {/* ë©”ì‹œì§€ ëª©ë¡ */}
      {messages.map((msg) => (
        <div key={msg.id} className={msg.role}>
          {msg.content}
        </div>
      ))}
      
      {/* ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì¸ ì‘ë‹µ */}
      {streamingContent && (
        <div className="assistant streaming">
          {streamingContent}
        </div>
      )}
      
      {/* ì—ëŸ¬ ì²˜ë¦¬ */}
      {error && (
        <div className="error">
          <p>{error.message}</p>
          <button onClick={retry}>ì¬ì‹œë„</button>
        </div>
      )}
      
      {/* ì…ë ¥ */}
      <input 
        onKeyDown={(e) => {
          if (e.key === 'Enter' && !e.shiftKey) {
            handleSend(e.currentTarget.value);
          }
        }}
        disabled={isLoading}
      />
      
      {isLoading && <button onClick={abort}>ì·¨ì†Œ</button>}
    </div>
  );
};
```

### 2. í›… ë¶„ë¦¬ ì‚¬ìš©

```tsx
// ì½ê¸° ì „ìš© ìƒíƒœë§Œ í•„ìš”í•  ë•Œ
const { messages, isLoading, error } = useChatState();

// ì•¡ì…˜ë§Œ í•„ìš”í•  ë•Œ
const { send, abort, clear, retry } = useChatActions();
```

### 3. ì„œë¹„ìŠ¤ ì§ì ‘ ì‚¬ìš©

```tsx
import { chatService, createChatService } from '@/features/chat';

// ê¸°ë³¸ ì‹±ê¸€í†¤ ì‚¬ìš©
const response = await chatService.sendMessage(
  messages,
  (chunk) => console.log(chunk.content),
  { streaming: true }
);

// ì»¤ìŠ¤í…€ ì„¤ì •ìœ¼ë¡œ ìƒì„±
const customService = createChatService({
  type: 'LLMAPI',
  streaming: true,
  llmProvider: 'anthropic',
  llmModel: 'claude-3-5-sonnet-20241022',
});
```

### 4. ìƒˆ ì„œë¹„ìŠ¤ ë“±ë¡

```tsx
import { registerService } from '@/features/chat';

// ì»¤ìŠ¤í…€ RAG ì„œë¹„ìŠ¤ ë“±ë¡
class RAGService implements ChatService {
  async sendMessage(messages, onChunk, options) {
    // RAG íŒŒì´í”„ë¼ì¸ êµ¬í˜„
  }
}

registerService('RAGService', (config) => new RAGService(config));

// í™˜ê²½ë³€ìˆ˜ë¡œ ì‚¬ìš©
// VITE_CHAT_SERVICE_TYPE=RAGService
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### í…ŒìŠ¤íŠ¸ êµ¬ì¡°

```
src/test/
â”œâ”€â”€ setup.ts                    # Vitest ì„¤ì •
â”œâ”€â”€ test-utils.tsx              # í…ŒìŠ¤íŠ¸ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ mocks/
â”‚   â””â”€â”€ MockLLMAdapter.ts       # LLM Mock
â”œâ”€â”€ api/
â”‚   â””â”€â”€ MockLLMAdapter.test.ts  # Mock ì–´ëŒ‘í„° í…ŒìŠ¤íŠ¸ (24ê°œ)
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ChatInput.test.tsx      # ì…ë ¥ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ (18ê°œ)
â”‚   â””â”€â”€ ChatMessage.test.tsx    # ë©”ì‹œì§€ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ (14ê°œ)
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useChat.test.tsx        # useChat í›… í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ useLLMChat.test.tsx     # LLM ì±„íŒ… í›… í…ŒìŠ¤íŠ¸ (15ê°œ)
â””â”€â”€ integration/
    â””â”€â”€ chat-flow.test.tsx      # í†µí•© í…ŒìŠ¤íŠ¸ (12ê°œ)
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# Watch ëª¨ë“œ
yarn test

# 1íšŒ ì‹¤í–‰
yarn test:run

# ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸
yarn test:coverage

# UI ëª¨ë“œ
yarn test:ui
```

### MockLLMAdapter ì‚¬ìš©

```tsx
import { MockLLMAdapter } from '@/test/mocks/MockLLMAdapter';

describe('Chat Feature', () => {
  it('should handle streaming response', async () => {
    const mock = new MockLLMAdapter({
      responses: ['Hello!', 'How can I help?'],
      streamDelay: 10,
    });

    const chunks: string[] = [];
    for await (const chunk of mock.stream({ messages: [] })) {
      chunks.push(chunk.content);
    }

    expect(chunks.join('')).toBe('Hello!');
  });

  it('should simulate error', async () => {
    const mock = new MockLLMAdapter({
      shouldError: true,
      errorType: 'rate_limit',
    });

    await expect(mock.chat({ messages: [] })).rejects.toThrow();
  });
});
```

---

## ğŸ”§ í™•ì¥ ê°€ì´ë“œ

### ìƒˆ LLM Provider ì¶”ê°€

`src/shared/api/llm/direct/adapters/`ì— ìƒˆ ì–´ëŒ‘í„° ìƒì„±:

```typescript
// NewProviderAdapter.ts
import type { LLMAdapter, LLMRequest, LLMResponse, LLMStreamChunk } from '../types';

export class NewProviderAdapter implements LLMAdapter {
  readonly name = 'new-provider';
  
  constructor(private config: LLMProviderConfig) {}

  async chat(request: LLMRequest): Promise<LLMResponse> {
    const response = await fetch('https://api.new-provider.com/chat', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.config.apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model: request.model || this.config.defaultModel,
        messages: request.messages,
      }),
    });
    
    const data = await response.json();
    return {
      content: data.content,
      model: data.model,
    };
  }

  async *stream(request: LLMRequest): AsyncGenerator<LLMStreamChunk> {
    // SSE ìŠ¤íŠ¸ë¦¬ë° êµ¬í˜„
  }
}
```

### createLLMì— ë“±ë¡

```typescript
// src/shared/api/llm/direct/index.ts
export function createLLM(options: CreateLLMOptions): LLMAdapter {
  switch (options.type) {
    case 'openai':
      return new OpenAIAdapter(options);
    case 'new-provider':  // ì¶”ê°€
      return new NewProviderAdapter(options);
    // ...
  }
}
```

### ìƒˆ ë©”ì‹œì§€ íƒ€ì… ì¶”ê°€

```tsx
// ì´ë¯¸ì§€ ë©”ì‹œì§€ ë Œë”ëŸ¬
const ImageMessage = ({ message }) => (
  <img src={message.metadata?.imageUrl} alt="uploaded" />
);

// ë Œë”ëŸ¬ ë“±ë¡
registerMessageRenderer('image', ImageMessage);
```

---

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

### Core

| ê¸°ìˆ  | ë²„ì „ | ìš©ë„ |
|------|------|------|
| TypeScript | 5.x | íƒ€ì… ì•ˆì „ì„± |
| React | 18.3 | UI í”„ë ˆì„ì›Œí¬ |
| Vite | 6.x | ë¹Œë“œ ë„êµ¬ |

### ë¼ìš°íŒ… & ë°ì´í„°

| ê¸°ìˆ  | ë²„ì „ | ìš©ë„ |
|------|------|------|
| TanStack Router | 1.x | íŒŒì¼ ê¸°ë°˜ ë¼ìš°íŒ… |
| TanStack Query | 5.x | ì„œë²„ ìƒíƒœ ê´€ë¦¬ |
| Recoil | 0.7 | í´ë¼ì´ì–¸íŠ¸ ìƒíƒœ ê´€ë¦¬ |

### UI & ìŠ¤íƒ€ì¼

| ê¸°ìˆ  | ë²„ì „ | ìš©ë„ |
|------|------|------|
| TailwindCSS | 3.x | ìœ í‹¸ë¦¬í‹° CSS |
| HeroUI | 2.x | UI ì»´í¬ë„ŒíŠ¸ |
| MUI | 6.x | UI ì»´í¬ë„ŒíŠ¸ |
| Framer Motion | 12.x | ì• ë‹ˆë©”ì´ì…˜ |

### í…ŒìŠ¤íŠ¸ & í’ˆì§ˆ

| ê¸°ìˆ  | ë²„ì „ | ìš©ë„ |
|------|------|------|
| Vitest | 3.x | í…ŒìŠ¤íŠ¸ ëŸ¬ë„ˆ |
| Testing Library | 16.x | ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸ |
| ESLint | 9.x | ì½”ë“œ ë¦°íŒ… |
| Prettier | - | ì½”ë“œ í¬ë§·íŒ… |

---

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
src/
â”œâ”€â”€ entities/                 # ë„ë©”ì¸ ì—”í‹°í‹°
â”‚   â”œâ”€â”€ chat/                 # ì±„íŒ…ë°© ê´€ë ¨ API
â”‚   â””â”€â”€ message-set/          # ë©”ì‹œì§€ ì„¸íŠ¸ íƒ€ì…
â”‚
â”œâ”€â”€ features/                 # ê¸°ëŠ¥ ë‹¨ìœ„ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ chat/                 # ğŸ’¬ ì±„íŒ… ê¸°ëŠ¥ (í•µì‹¬)
â”‚   â”‚   â”œâ”€â”€ atom/             # Recoil ìƒíƒœ
â”‚   â”‚   â”œâ”€â”€ hooks/            # React í›…
â”‚   â”‚   â”œâ”€â”€ lib/              # ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”œâ”€â”€ services/         # ChatService êµ¬í˜„
â”‚   â”‚   â”œâ”€â”€ types/            # íƒ€ì… ì •ì˜
â”‚   â”‚   â””â”€â”€ ui/               # UI ì»´í¬ë„ŒíŠ¸
â”‚   â””â”€â”€ layout/               # ë ˆì´ì•„ì›ƒ ê´€ë ¨
â”‚
â”œâ”€â”€ routes/                   # í˜ì´ì§€ ë¼ìš°íŠ¸
â”‚   â”œâ”€â”€ __root.tsx            # ë£¨íŠ¸ ë ˆì´ì•„ì›ƒ
â”‚   â”œâ”€â”€ index.tsx             # í™ˆ í˜ì´ì§€
â”‚   â””â”€â”€ chat.tsx              # ì±„íŒ… í˜ì´ì§€
â”‚
â”œâ”€â”€ shared/                   # ê³µìœ  ëª¨ë“ˆ
â”‚   â”œâ”€â”€ api/                  # API í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â””â”€â”€ llm/              # ğŸ”Œ LLM ì–´ëŒ‘í„°
â”‚   â”‚       â”œâ”€â”€ direct/       # ì§ì ‘ ì—°ê²° ì–´ëŒ‘í„°
â”‚   â”‚       â”‚   â””â”€â”€ adapters/ # OpenAI, Anthropic, Gemini
â”‚   â”‚       â””â”€â”€ server/       # ì„œë²„ ê²½ìœ  í´ë¼ì´ì–¸íŠ¸
â”‚   â”œâ”€â”€ constants/            # ìƒìˆ˜, enum
â”‚   â”œâ”€â”€ context/              # React Context
â”‚   â”œâ”€â”€ hooks/                # ê³µìš© í›…
â”‚   â”œâ”€â”€ lib/                  # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”œâ”€â”€ types/                # ê³µìš© íƒ€ì…
â”‚   â””â”€â”€ ui/                   # ê³µìš© UI ì»´í¬ë„ŒíŠ¸
â”‚
â”œâ”€â”€ styles/                   # ì „ì—­ ìŠ¤íƒ€ì¼
â”‚   â””â”€â”€ globals.css           # TailwindCSS
â”‚
â”œâ”€â”€ test/                     # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ mocks/                # Mock ê°ì²´
â”‚   â”œâ”€â”€ api/                  # API í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ components/           # ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ hooks/                # í›… í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ integration/          # í†µí•© í…ŒìŠ¤íŠ¸
â”‚
â””â”€â”€ ui/                       # ì•± ë ˆë²¨ UI
    â””â”€â”€ ModalOutlet.tsx       # ëª¨ë‹¬ ì•„ì›ƒë ›

public/
â””â”€â”€ locales/                  # ë‹¤êµ­ì–´ ë²ˆì—­ íŒŒì¼
    â”œâ”€â”€ en/                   # ì˜ì–´
    â””â”€â”€ ko/                   # í•œêµ­ì–´
```

---

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

Copyright (c) 2026